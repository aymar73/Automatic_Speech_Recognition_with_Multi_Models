{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# environment: tensorflow 1.2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import utils\n",
    "import cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's <type 'list'>, length: 4620, each element has <type 'numpy.ndarray'>\n",
      "train_label's <type 'list'>, length: 4620, each element has <type 'numpy.ndarray'>\n",
      "test_data's <type 'list'>, length: 1680, each element has <type 'numpy.ndarray'>\n",
      "test_label's <type 'list'>, length: 1680, each element has <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "########## Read data ##########\n",
    "\n",
    "train_data_dir = \"./data/TIMIT/phn/train/mfcc/\"\n",
    "train_label_dir = \"./data/TIMIT/phn/train/label/\"\n",
    "test_data_dir = \"./data/TIMIT/phn/test/mfcc/\"\n",
    "test_label_dir = \"./data/TIMIT/phn/test/label/\"\n",
    "\n",
    "#each one is a list of 2D ([feature_num, time_step]) numpy data\n",
    "train_data = utils.read_ndarray_from(train_data_dir) \n",
    "train_label = utils.read_ndarray_from(train_label_dir)\n",
    "test_data = utils.read_ndarray_from(test_data_dir)\n",
    "test_label = utils.read_ndarray_from(test_label_dir)\n",
    "\n",
    "train_label_ind, train_label_val, train_label_shape = utils.sparse_tuple_from(train_label)\n",
    "test_label_ind, test_label_val, test_label_shape = utils.sparse_tuple_from(test_label)\n",
    "# Make a glance of data\n",
    "print(\"{}'s {}, length: {}, each element has {}\"\\\n",
    "      .format(\"train_data\", type(train_data), len(train_data), type(train_data[0])))\n",
    "print(\"{}'s {}, length: {}, each element has {}\"\\\n",
    "      .format(\"train_label\", type(train_label), len(train_label), type(train_label[0])))\n",
    "print(\"{}'s {}, length: {}, each element has {}\"\\\n",
    "      .format(\"test_data\", type(test_data), len(test_data), type(test_data[0])))\n",
    "print(\"{}'s {}, length: {}, each element has {}\"\\\n",
    "      .format(\"test_label\", type(test_label), len(test_label), type(test_label[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "########## Define Hyper-parameters ##########\n",
    "class Argument(object):\n",
    "    def __init__(self):\n",
    "        self.max_epoch = 100\n",
    "        self.num_layers = 2\n",
    "        self.num_hidden = 50\n",
    "        self.num_classes = 30 \n",
    "        self.batch_size = 32\n",
    "        self.learning_rate = 0.001\n",
    "        self.layer_norm = True\n",
    "        self.dropout_prob = 0.1\n",
    "        self.dropout_keep_prob = 1- self.dropout_prob\n",
    "        \n",
    "        self.num_feature = train_data[0].shape[0]\n",
    "        self.max_timestep = utils.get_max_timestep(train_data, test_data)\n",
    "        \n",
    "        self.layer_norm = True\n",
    "        self.cell_type = 'LSTMCell' #option: LSTMCell, RNNCell, GRUCell\n",
    "        self.activation = 'tanh' #option: tanh, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense/BiasAdd:0\", shape=(32, 778, 30), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "########## Define a model ##########\n",
    "\n",
    "args = Argument()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(dtype=tf.float32, shape=[args.batch_size, args.max_timestep, args.num_feature], name=\"inputs\")\n",
    "    targets = tf.sparse_placeholder(tf.int32, name=\"targets\")\n",
    "    seq_len = tf.placeholder(tf.int32, [args.batch_size], name=\"seq_len\")\n",
    "    \n",
    "    #stack multi-layers cells\n",
    "    stacked_cells = []\n",
    "    for i in range(args.num_layers):\n",
    "        cell = cells.select_cell(args)\n",
    "        stacked_cells.append(cell)\n",
    "        \n",
    "    mul_cells = tf.contrib.rnn.MultiRNNCell(stacked_cells)\n",
    "    \n",
    "    #use dynamic rnn to get output lists and deprecated the last state\n",
    "    #output shape: [batch_size, max_timesteps, num_hidden]\n",
    "    output, _ = tf.nn.dynamic_rnn(mul_cells, inputs, seq_len, dtype=tf.float32)\n",
    "    \n",
    "    #define full connect layer\n",
    "    output = tf.layers.dense(output, args.num_classes)\n",
    "    print(output)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
